<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Christopher&#39;s Portfolio</title>
    <link>http://christophermadsen.github.io/</link>
      <atom:link href="http://christophermadsen.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>Christopher&#39;s Portfolio</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Fri, 29 Jan 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>http://christophermadsen.github.io/media/avatar.jpg</url>
      <title>Christopher&#39;s Portfolio</title>
      <link>http://christophermadsen.github.io/</link>
    </image>
    
    <item>
      <title>Bachelor Thesis</title>
      <link>http://christophermadsen.github.io/project/thesis/</link>
      <pubDate>Fri, 29 Jan 2021 00:00:00 +0000</pubDate>
      <guid>http://christophermadsen.github.io/project/thesis/</guid>
      <description>&lt;h3 id=&#34;key-takeaways&#34;&gt;Key Takeaways&lt;/h3&gt;
&lt;p&gt;While working on my bachelor thesis I learnt a great many things, including the following; The PyTorch deep learning framework for building models, processing image data, working on GPUs and loading data with multithreading. Advanced image data processing methods. Utilizing transfer learning and fine-tuning models to perform well on data from a different domain. Explaining and visualizing the decision making of a convolutional model through class activation mapping (CAM). Reading and applying knowledge from research papers.&lt;/p&gt;
&lt;h3 id=&#34;introduction&#34;&gt;Introduction&lt;/h3&gt;
&lt;p&gt;My thesis involved investigating and building a simpler convolutional model for recognising Christian saints in renaissance artworks by the most distinct visual features from their respective iconography. Such features could be the arrows piercing Saint Sebastian, the ointment jar of Mary Magdalene or the lion accompanying Saint Jerome. This was to find a baseline for the aforementioned task and investigate how complex/deep such a model needed to be to base its decision on the iconography of the saint.&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-examples-of-the-data&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;http://christophermadsen.github.io/project/thesis/intropic_hua8d5c8d706054f8fcf7c5db85b7a6f95_272058_2000x2000_fit_q90_lanczos.jpg&#34; data-caption=&#34;Examples of the data&#34;&gt;


  &lt;img data-src=&#34;http://christophermadsen.github.io/project/thesis/intropic_hua8d5c8d706054f8fcf7c5db85b7a6f95_272058_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;1342&#34; height=&#34;740&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
    Examples of the data
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;&lt;strong&gt;A link to my thesis is at the top of this page.&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;the-model&#34;&gt;The model&lt;/h3&gt;
&lt;p&gt;The model chosen was a VGG-16, pretrained on the ImageNet data set. I fine-tuned it on the ArtDL data set (data set of the Christian saints) with 3 different training strategies of varying data pre-processing techniques and different choices of frozen layers. In addition I modified the model to be fully convolutional and generate class activation mappings showing heatmaps of the features used for inference. The most successful strategy involved freezing the input layer, the first convolutional block and half of the second, together with image normalization, random erasing augmentation and expansion of the data to minimize class imbalance.&lt;/p&gt;
&lt;h3 id=&#34;results&#34;&gt;Results&lt;/h3&gt;
&lt;p&gt;The final macro averages of the model results were:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Precision&lt;/th&gt;
&lt;th&gt;Recall&lt;/th&gt;
&lt;th&gt;F1&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0.61&lt;/td&gt;
&lt;td&gt;0.25&lt;/td&gt;
&lt;td&gt;0.31&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The precision was rather high for a baseline model, but the low recall and further investigation showed bias towards Virgin Mary, the class with significantly more data than the rest. This was mainly due to the relatively shallow depth of the model compared to the state-of-art, a ResNet50. The investigation showed that a model of only 16 layers of depth isn&amp;rsquo;t deep enough for more abstract features such as the entirety of Mary Magdalene&amp;rsquo;s ointment jar. Further investigation showed that in many cases the baseline model extracted similar features or parts of more abstract features used by the state-of-art model. Example is nudity textures together with arrow lines, versus the specific arrow penetration areas for Saint Sebastian, or the texture of Mary Magdalene&amp;rsquo;s curly hair and lines of the ointment jar, versus specifically the ointment jar.&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-cams-from-the-vgg-16-model-1&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;http://christophermadsen.github.io/project/thesis/thesis1_hu403907a8f02ca8065492bafac2c11899_9213565_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;CAMs from the VGG-16 model (1)&#34;&gt;


  &lt;img data-src=&#34;http://christophermadsen.github.io/project/thesis/thesis1_hu403907a8f02ca8065492bafac2c11899_9213565_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;4000&#34; height=&#34;1543&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
    CAMs from the VGG-16 model (1)
  &lt;/figcaption&gt;


&lt;/figure&gt;







  



  
  











&lt;figure id=&#34;figure-cams-from-the-vgg-16-model-2&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;http://christophermadsen.github.io/project/thesis/thesis2_hud0f10b99d2db9880fe75492ae00033be_11268404_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;CAMs from the VGG-16 model (2)&#34;&gt;


  &lt;img data-src=&#34;http://christophermadsen.github.io/project/thesis/thesis2_hud0f10b99d2db9880fe75492ae00033be_11268404_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;4000&#34; height=&#34;2009&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
    CAMs from the VGG-16 model (2)
  &lt;/figcaption&gt;


&lt;/figure&gt;

</description>
    </item>
    
    <item>
      <title>Prediction of Atrial Fibrillation</title>
      <link>http://christophermadsen.github.io/project/amc-afib/</link>
      <pubDate>Fri, 01 Jun 2018 00:00:00 +0000</pubDate>
      <guid>http://christophermadsen.github.io/project/amc-afib/</guid>
      <description>&lt;h3 id=&#34;key-takeaways&#34;&gt;Key Takeaways&lt;/h3&gt;
&lt;p&gt;This project taught me advanced data processing techniques, how to work with neural networks in practice, the Keras deep learning framework and how to work Agile within a team.&lt;/p&gt;
&lt;h3 id=&#34;introduction&#34;&gt;Introduction&lt;/h3&gt;
&lt;p&gt;This was my 2nd year project on my BSc edducation and was offered to my team by a PhD student at the Amsterdam Medical Center (AMC). Our team of 5 worked intensively on the project over the course of 1 month and in parallel were also trained to work in the agile framework Scrum.&lt;/p&gt;
&lt;h3 id=&#34;short-summary&#34;&gt;Short Summary&lt;/h3&gt;
&lt;p&gt;We took on the task of finding patterns in electrocardiograms (ECG) for prediction of abnormalities such as Atrial Fibrillation. We applied various data processing techniques including but not limited to Discrete Fourier Transform and Savitzky-Golay smoothing. The final model consisted of a fully connected Neural Network which was capable of predicting Atrial Fibrillation with high accuracy. The project was a success and part of the team went on to work further with the PhD student which resulted in the improved project being published in a journal.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Links to the slides and the paper are at the top of this page.&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;the-project&#34;&gt;The Project&lt;/h3&gt;
&lt;p&gt;We received a large set of tagged (specific heart diseases) ECG data. This set contained the ECGs of 1Ìƒ500 people, each divided in 8 channels consisting of 5000 data points each.&lt;/p&gt;
&lt;p&gt;Our client was a PhD (medicine) student working for the AMC. She (and her colleagues) had been tagging the ECGs and were seeking help from competent AI students to perform deep learning on their data.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Example data&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;





  



  
  











&lt;figure id=&#34;figure-healthy-sinus-rhytm&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;http://christophermadsen.github.io/project/amc-afib/healthy_hu3f6794374f91fe471999361c00f55cf9_28008_2000x2000_fit_q90_lanczos.jpg&#34; data-caption=&#34;Healthy sinus rhytm&#34;&gt;


  &lt;img data-src=&#34;http://christophermadsen.github.io/project/amc-afib/healthy_hu3f6794374f91fe471999361c00f55cf9_28008_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;640&#34; height=&#34;480&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
    Healthy sinus rhytm
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/td&gt;
&lt;td&gt;





  



  
  











&lt;figure id=&#34;figure-aarhytmia&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;http://christophermadsen.github.io/project/amc-afib/arrhytmia_hu9fec98b262764ad189fca710ba611b39_26343_2000x2000_fit_q90_lanczos.jpg&#34; data-caption=&#34;Aarhytmia&#34;&gt;


  &lt;img data-src=&#34;http://christophermadsen.github.io/project/amc-afib/arrhytmia_hu9fec98b262764ad189fca710ba611b39_26343_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;640&#34; height=&#34;480&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
    Aarhytmia
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The goal of the 4 week project was to explore feature extraction methods (in signal processing) and to train a Neural Network that would have an accuracy of at least 70% in predicting the tagged heart diseases in the data.&lt;/p&gt;
&lt;h4 id=&#34;preprocessing&#34;&gt;Preprocessing&lt;/h4&gt;
&lt;p&gt;With Savitzky-Golay smoothing we reduced the noise in the ECGs.&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-noisey-signal-and-smoothed-signal&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;http://christophermadsen.github.io/project/amc-afib/ecg_noise_smooth_hu9d79cbd6c68f59f0929a08f468fec7da_27834_2000x2000_fit_q90_lanczos.jpg&#34; data-caption=&#34;Noisey signal and smoothed signal&#34;&gt;


  &lt;img data-src=&#34;http://christophermadsen.github.io/project/amc-afib/ecg_noise_smooth_hu9d79cbd6c68f59f0929a08f468fec7da_27834_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;640&#34; height=&#34;480&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
    Noisey signal and smoothed signal
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;With Fourier Analysis we corrected for baseline wandering in the ECGs.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Baseline Wandering&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;





  



  
  











&lt;figure id=&#34;figure-detecting-a-wandering-baseline&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;http://christophermadsen.github.io/project/amc-afib/baseline_detection_hub2431205ae7912f5d2491bada002ece5_47193_2000x2000_fit_q90_lanczos.jpg&#34; data-caption=&#34;Detecting a wandering baseline&#34;&gt;


  &lt;img data-src=&#34;http://christophermadsen.github.io/project/amc-afib/baseline_detection_hub2431205ae7912f5d2491bada002ece5_47193_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;640&#34; height=&#34;480&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
    Detecting a wandering baseline
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/td&gt;
&lt;td&gt;





  



  
  











&lt;figure id=&#34;figure-correcting-the-baseline&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;http://christophermadsen.github.io/project/amc-afib/baseline_correction_all_hu218db62af0f80b9778fd952705d7dcdb_59679_2000x2000_fit_q90_lanczos.jpg&#34; data-caption=&#34;Correcting the baseline&#34;&gt;


  &lt;img data-src=&#34;http://christophermadsen.github.io/project/amc-afib/baseline_correction_all_hu218db62af0f80b9778fd952705d7dcdb_59679_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;640&#34; height=&#34;480&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
    Correcting the baseline
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;We extracted the pulses from the ECGs and scaled them to a fixed size. Overlaying them showed a clear division between healthy and unhealthy.&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-overlapping-scaled-pulses&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;http://christophermadsen.github.io/project/amc-afib/pulses_hu72a889210d09b3994876450892db6b92_855088_2000x2000_fit_q90_lanczos.jpg&#34; data-caption=&#34;Overlapping scaled pulses&#34;&gt;


  &lt;img data-src=&#34;http://christophermadsen.github.io/project/amc-afib/pulses_hu72a889210d09b3994876450892db6b92_855088_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;1920&#34; height=&#34;935&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
    Overlapping scaled pulses
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h4 id=&#34;the-model&#34;&gt;The model&lt;/h4&gt;
&lt;p&gt;The model we used for predicting Atrial Fibrillation was a relatively deep fully connected Neural Network (Multi-layer Perceptron). We used the preprocessed pulses as input and trained it on a binary classification of Sinus Rhythm and Atrial Fibrillation.&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-layer-representation-of-the-model&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;http://christophermadsen.github.io/project/amc-afib/afib-model_hu9abbd3abd5fe060e6d02f67d7bc4e650_39942_2000x2000_fit_q90_lanczos.JPG&#34; data-caption=&#34;Layer representation of the model&#34;&gt;


  &lt;img data-src=&#34;http://christophermadsen.github.io/project/amc-afib/afib-model_hu9abbd3abd5fe060e6d02f67d7bc4e650_39942_2000x2000_fit_q90_lanczos.JPG&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;396&#34; height=&#34;513&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
    Layer representation of the model
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h4 id=&#34;results&#34;&gt;Results&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Accuracy&lt;/th&gt;
&lt;th&gt;Precision&lt;/th&gt;
&lt;th&gt;Recall&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0.96&lt;/td&gt;
&lt;td&gt;0.95&lt;/td&gt;
&lt;td&gt;0.96&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The final prediction results of the model were surprisingly good and exceeded our expectations.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Training metrics&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;





  



  
  











&lt;figure id=&#34;figure-accuracy-per-epoch&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;http://christophermadsen.github.io/project/amc-afib/acc_epoch_hu5c97223b3817c63113d18bbd153c21b9_34199_2000x2000_fit_q90_lanczos.jpg&#34; data-caption=&#34;Accuracy per epoch&#34;&gt;


  &lt;img data-src=&#34;http://christophermadsen.github.io/project/amc-afib/acc_epoch_hu5c97223b3817c63113d18bbd153c21b9_34199_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;640&#34; height=&#34;480&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
    Accuracy per epoch
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/td&gt;
&lt;td&gt;





  



  
  











&lt;figure id=&#34;figure-loss-per-epoch&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;http://christophermadsen.github.io/project/amc-afib/acc_loss_huf7155a4dbfc92ce8c58b4b920f96d20d_35858_2000x2000_fit_q90_lanczos.jpg&#34; data-caption=&#34;Loss per epoch&#34;&gt;


  &lt;img data-src=&#34;http://christophermadsen.github.io/project/amc-afib/acc_loss_huf7155a4dbfc92ce8c58b4b920f96d20d_35858_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;640&#34; height=&#34;480&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption data-pre=&#34;Figure &#34; data-post=&#34;:&#34; class=&#34;numbered&#34;&gt;
    Loss per epoch
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Our goal was to surpass at least 70% accuracy and we achieved 96%. The project was a success and we were satisfied.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
